{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# =========================================================\n",
    "# --- 0. Import bibliotek ---\n",
    "# =========================================================\n",
    "#pip install numpy\n",
    "#pip install matplotlib\n",
    "#pip install keras\n",
    "#pip install tensorflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    "    MaxPooling2D,\n",
    "    GlobalAveragePooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Dropout\n",
    ")\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =========================================================\n",
    "# --- 1. Importowanie danych CIFAR10 ---\n",
    "# =========================================================\n",
    "# Wczytanie zbioru danych CIFAR10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Wyświetlenie przykładowego obrazu (opcjonalne)\n",
    "print(\"Etykieta przykładowego obrazu:\", y_train[0])\n",
    "plt.imshow(x_train[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "9261a53887375be5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =========================================================\n",
    "# --- 2. Wstępne przetwarzanie danych ---\n",
    "# =========================================================\n",
    "# Normalizacja do zakresu [0,1] i dodanie kanału (H,W,1)\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test  = x_test.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encoding etykiet\n",
    "num_classes = 10\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat  = to_categorical(y_test, num_classes)\n",
    "\n",
    "# lista nazw klas CIFAR-10 (użyteczna w wyświetleniach)\n",
    "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
   ],
   "id": "52a83d265653efe3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "dodanie sieci BathNormalization dla unikniecia przetrenowania modelu oraz dla stabilizacji gradientu (bo tutaj sa bardzo rozpikselowane obrazy)\n",
    "po tej zmianie var_loss z 0.93 na 0.83\n",
    "\n",
    "oryginalne dane:\n",
    "\n",
    "    model = Sequential([\n",
    "      oryginalna werjsa\n",
    "      Input(shape=input_shape),\n",
    "      Conv2D(32, (3,3), activation='relu'),\n",
    "      MaxPooling2D((2,2)),\n",
    "      Conv2D(64, (3,3), activation='relu'),\n",
    "      MaxPooling2D((2,2)),\n",
    "      Flatten(),\n",
    "      Dense(64, activation='relu'),\n",
    "      Dense(num_classes, activation='softmax')\n",
    "    ])"
   ],
   "id": "102e6c17981f4fc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =========================================================\n",
    "# --- 3. Definicja modelu sieci neuronowej ---\n",
    "# =========================================================\n",
    "input_shape = (32, 32, 3)  # CIFAR-10 to 32x32 RGB\n",
    "\n",
    "#todo opisac co siedzieje po kolei\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "\n",
    "    #---------\n",
    "    Conv2D(32, (3,3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Dropout(0.1),#todo opisac co robi dropout\n",
    "\n",
    "    #---------\n",
    "    Conv2D(64, (3,3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Dropout(0.2),\n",
    "\n",
    "    #---------\n",
    "\n",
    "    #siec gesta\n",
    "    Flatten(),\n",
    "    Dense(128),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ],
   "id": "b1e21ec02e2e9701"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Zmiana: optimizer = Adam (learing_rate =  1e-2) na learning_rate = 1e-3 -> to zmniejsza niestabilnosc walidacji, program nie \"skacze\" po wynikach tylko przechodzi powoli\n",
    "\n",
    "to zmienia oryginalne 1.35 var_loss na 0.93"
   ],
   "id": "b39ae1ada249daaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =========================================================\n",
    "# --- 4. Kompilacja modelu ---\n",
    "# =========================================================\n",
    "# Optymalizator Adam, funkcja straty categorical_crossentropy, metryka accuracy\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),#todo opisac co dokladnie robi adam\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Wyświetlenie podsumowania modelu\n",
    "model.summary()"
   ],
   "id": "7b227a34ef0dba21"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "zmiana w EarlyStopping -> monitorujemy val_loss wiec na tym trzeba sie skupic, dodatkowo przywrocenie najlepszych wag na true, oraz zmiana patience na 5\n",
    "\n",
    "zmiana w ReduceLROnPlateau -> tak samo, monitorowanie val_loss zamiast val_accuracy, zmiana patience na 3\n",
    "\n",
    "oryginalna wersja (ale po moich zmianach):\n",
    "\n",
    "    es = EarlyStopping(\n",
    "      monitor='val_accuracy',   # metryka, którą obserwujemy (np. val_loss, val_accuracy)\n",
    "      patience=6,               # liczba epok bez poprawy, po których zatrzymujemy trening\n",
    "      min_delta=1e-5,           # minimalna wymagana zmiana, by uznać, że jest „poprawa”\n",
    "      mode='max'              # 'min' jeśli monitorujemy straty, 'max' jeśli dokładność\n",
    "    )\n",
    "    rlp = ReduceLROnPlateau(\n",
    "      monitor='val_accuracy',   # metryka do obserwacji\n",
    "      factor=0.5,           # ile razy zmniejszyć LR (tu: o połowę)\n",
    "      patience=6,           # liczba epok bez poprawy przed zmniejszeniem LR, rlp.patience < es.patience\n",
    "      min_delta=1e-5,       # próg czułości jak wyżej\n",
    "      min_lr=1e-4,          # dolna granica learning rate\n",
    "      mode='max',           # 'min' dla strat, 'max' dla dokładności\n",
    "    )\n",
    "\n",
    "to zmniejsza var_loss z okolo 0.70 na 0.66"
   ],
   "id": "ef91a7aeafb1f02a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =========================================================\n",
    "# --- 5. Trenowanie modelu ---\n",
    "# =========================================================\n",
    "es = EarlyStopping(\n",
    "    monitor='val_loss',   # metryka, którą obserwujemy (np. val_loss, val_accuracy)\n",
    "    patience=5,               # liczba epok bez poprawy, po których zatrzymujemy trening\n",
    "    min_delta=1e-5,           # minimalna wymagana zmiana, by uznać, że jest „poprawa”\n",
    "    mode='min',              # 'min' jeśli monitorujemy straty, 'max' jeśli dokładność\n",
    "    restore_best_weights=True\n",
    ")\n",
    "rlp = ReduceLROnPlateau(\n",
    "    monitor='val_loss',   # metryka do obserwacji\n",
    "    factor=0.5,           # ile razy zmniejszyć LR (tu: o połowę)\n",
    "    patience=3,           # liczba epok bez poprawy przed zmniejszeniem LR, rlp.patience < es.patience\n",
    "    min_delta=1e-5,       # próg czułości jak wyżej\n",
    "    min_lr=1e-5,          # dolna granica learning rate\n",
    "    mode='min',           # 'min' dla strat, 'max' dla dokładności\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train_cat,\n",
    "    batch_size=64,\n",
    "    epochs=25,\n",
    "    validation_data=(x_test, y_test_cat),\n",
    "    callbacks=[es, rlp],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Data skończenia treningu - timestamp - znacznik do zapisywania plików\n",
    "ts = datetime.datetime.now().strftime(\"_%Y%m%d_%H%M\")"
   ],
   "id": "adff31e0a2caf5f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =========================================================\n",
    "# --- 6. Ewaluacja modelu ---\n",
    "# =========================================================\n",
    "loss, accuracy = model.evaluate(x_test, y_test_cat, verbose=0)\n",
    "print('Dokładność na zbiorze testowym:', f\"{accuracy:.2f}\")\n",
    "print('Strata na zbiorze testowym:', f\"{loss:.2f}\")"
   ],
   "id": "b03ff61e8dcdaed3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =========================================================\n",
    "# --- 7. Wizualizacja przebiegu treningu (loss) ---\n",
    "# =========================================================\n",
    "fig_loss_acc = plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='loss (train)')\n",
    "plt.plot(history.history['val_loss'], label='loss (val)')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('categorical_crossentropy')\n",
    "plt.title(f'Strata na zbiorze testowym to {loss:.2f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label='accuracy (train)')\n",
    "plt.plot(history.history['val_accuracy'], label='accuracy (val)')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f\"Dokładność na zbiorze testowym to {accuracy:.2f}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Zapis wykresu\n",
    "#loss_acc_path = os.path.join(base_export_dir, f'training_loss_accuracy{ts}.png')\n",
    "#fig_loss_acc.savefig(loss_acc_path)\n",
    "#print(\"Zapisano wykres loss/accuracy ->\", loss_acc_path)\n",
    "\n",
    "plt.show()"
   ],
   "id": "8546c2a8a66c9404"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =========================================================\n",
    "# --- 8. Wizualizacja błędnych klasyfikacji i macierz pomyłek ---\n",
    "# =========================================================\n",
    "# Predykcje (etykiety)\n",
    "pred_probs = model.predict(x_test)\n",
    "pred_labels = np.argmax(pred_probs, axis=1)\n",
    "true_labels = np.argmax(y_test_cat, axis=1)  # lub po prostu y_test\n",
    "\n",
    "# Indeksy błędnych klasyfikacji\n",
    "incorrect_indices = np.nonzero(pred_labels != true_labels)[0]\n",
    "\n",
    "# Wyświetlenie kilku błędnych przykładów\n",
    "n_show = min(3, len(incorrect_indices))\n",
    "for i in range(n_show):\n",
    "    idx = incorrect_indices[i]\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(x_test[idx].squeeze(), cmap='gray')\n",
    "    plt.title(f\"Prawidłowo: {class_names[true_labels[idx]]}  -> Predykcja: {class_names[pred_labels[idx]]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "fig_cm, ax = plt.subplots(figsize=(8,8))\n",
    "disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
    "plt.title('Macierz pomyłek')\n",
    "# Zapis wykresu\n",
    "#loss_acc_path = os.path.join(base_export_dir, f'confusion_matrix{ts}.png')\n",
    "#fig_cm.savefig(loss_acc_path)\n",
    "#print(\"Zapisano macierz pomyłek ->\", loss_acc_path)\n",
    "plt.show()\n"
   ],
   "id": "264f35fea7ca8a02"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
